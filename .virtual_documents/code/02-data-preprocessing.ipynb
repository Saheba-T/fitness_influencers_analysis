import os
import re
import ast
import pandas as pd
import numpy as np
import spacy         # Natural language processing
import isodate       # Date transformation and manipulation

from dateutil import parser


# Read in the csv files from the raw data folder
channels_df = pd.read_csv("../data/raw/fitness_channels_2023_06_28.csv")
videos_df = pd.read_csv("../data/raw/fitness_videos_2023_06_28.csv")


channels_df.head()


videos_df.head()


# check for duplicate rows in channels and videos data
(channels_df.duplicated().any(),videos_df.duplicated().any())


channels_df.isnull().any()


videos_df.isnull().any()


# Find the percentage of missing values from columns that contains them in the videos dataframe
missingval_columns = videos_df.loc[:, ['description', 'tags', 'likeCount','favouriteCount','commentCount']]
missingval_columns.isnull().sum() / missingval_columns.shape[0] * 100.00


# Drop the favouriteCount column since it only contains missing values
videos_df.drop('favouriteCount', axis=1, inplace=True)


# Find the unique values of the definition column
videos_df['definition'].unique()


# Check the percentage of each unique value in the definition column
videos_df['definition'].value_counts() / videos_df['definition'].shape[0] * 100


# Drop the definition column for being uninformative
videos_df.drop('definition', axis=1, inplace=True)


# Check the date values to make sure there are no errors
videos_df.publishedAt.sort_values()


channels_df.dtypes


videos_df.dtypes


# Convert duration to seconds
videos_df['durationSecs'] = videos_df['duration'].apply(lambda x: isodate.parse_duration(x))
videos_df['durationMins'] = videos_df['durationSecs'].astype('timedelta64[s]')/60


# Check the distribution of the video duration for presence of any outliers
videos_df['durationMins'].describe()


# Check for videos that are longer than 45 mins
videos_df[videos_df['durationMins'] > 45][['channelTitle','title','duration','durationSecs','video_id']]


# list of ids of videos longer than 45 mins whose title clearly indicates are not workout videos
videos_to_drop = ['IdO0Ie3_2QU', 'HO84VmEkfq0', '0o4JRqqZmb4', 'G25aQB1sCWQ', 'wmF_P2QhB3M']

# Drop those videos in the list above from the videos data
videos_df = videos_df[~videos_df['video_id'].isin(videos_to_drop)]


# Check the distribution of video duration again after removal of nonworkout videos
videos_df['durationMins'].describe()


# Create publish datetime and year for channels data
channels_df['publishedDatetime'] =  channels_df['PublishedDate'].apply(lambda x: parser.parse(x))
channels_df['publishedYear'] = channels_df['publishedDatetime'].apply(lambda x: int(x.strftime("%Y")))

# Create publish year and month (of the year) columns
videos_df['publishedDatetime'] = videos_df['publishedAt'].apply(lambda x: parser.parse(x))
videos_df['publishedYear'] = videos_df['publishedDatetime'].apply(lambda x: int(x.strftime("%Y")))
videos_df['publishedMonth'] = videos_df['publishedDatetime'].apply(lambda x: x.strftime("%b"))

# Create publish day (of the week) and hour columns
videos_df['pushblishDayName'] = videos_df['publishedDatetime'].apply(lambda x: x.strftime("%a")) 
videos_df['publishedHour'] = videos_df['publishedDatetime'].apply(lambda x: x.strftime("%H"))


# Title character length
videos_df['titleLength'] = videos_df['title'].apply(lambda x: len(x))

# Create the number of tags column
videos_df['tags'] = videos_df['tags'].replace(np.nan, None)
videos_df['tags'] = videos_df['tags'].apply(lambda x: x if x is None else ast.literal_eval(x))
videos_df['tagsCount'] = videos_df['tags'].apply(lambda x: 0 if x is None else len(x))


# Now we are going to use spaCy's entity ruler along with regex 
# to extract entities from the text columns.

# Download spaCy's small english model
nlp = spacy.load("en_core_web_sm")

# Create and add the EntityRuler
ruler = nlp.add_pipe("entity_ruler", before="ner")


#List of Entities and Patterns
patterns = [
    {"label": "WORKOUT_TIME", "pattern": [{"TEXT": {"REGEX": r"^(\d+)"}},
                                          {"LOWER":{"REGEX": r"^(min|mins|minute|minutes|hour|hours|hr|hrs)$"}}
                                         ]},
    {"label": "FULL_BODY", "pattern": [{"LOWER": {"REGEX": r"(full|total|whole)"}}, {"LOWER": "body"}]},
    {"label": "UPPER_BODY", "pattern": [{"LOWER": "upper"}, {"LOWER": "body"}]},
    {"label": "LOWER_BODY", "pattern": [{"LOWER": "lower"}, {"LOWER": "body"}]},
    {"label": "CHEST_BACK", "pattern": [{"LOWER": {"REGEX": r"(back|chest)"}}, {"ORTH": {"REGEX": r"(and|&)?"}} ,{"LOWER": {"REGEX": r"(back|chest)?"}}]},
    {"label": "ABS", "pattern": [{"LOWER": {"REGEX": r"(core|ab|abs|plank)"}}]},
    {"label": "ARMS", "pattern": [{"LOWER": {"REGEX": r"arms?"}}]},
    {"label": "LEGS", "pattern": [{"LOWER": {"REGEX": r"(thigh|thighs|leg|legs)"}}]},
    {"label": "GLUTES", "pattern": [{"LOWER": {"REGEX": r"(booty|glute|glutes|butt)"}}]},
    {"label": "WORKOUT_TYPE", "pattern": [{"LOWER": {"REGEX": r"(hiit|cardio|pilates|yoga|dance|tabata|barre|stretch)"}}]},
    {"label": "STANDING", "pattern": [{"LOWER": "standing"}]},
    {"label": "NO_EQUIPMENT", "pattern": [{"LOWER": "no", "LOWER": {"REGEX": r"(equip|equipment|equipments|weight|weights)"}}]},
    {"label": "NO_JUMPING", "pattern": [{"LOWER": "no", "LOWER": "jumping"}]},
    {"label": "LOW_IMPACT", "pattern": [{"LOWER": "low", "LOWER": "impact"}]},
    {"label": "STRENGTH_TRAINING", "pattern": [{"LOWER": {"REGEX": r"(strength|sculpt|sculpting|tone|toning|toned)"}}]}
]


ruler.add_patterns(patterns)


# Extract workout time or type using regular expressions
def extract_ent_text(string, label):
    doc = nlp(string)
    workout_label = None
    for ent in doc.ents:
        if ent.label_ == label:
            workout_label = ent.text
            break
    return workout_label


# Function to convert workout time units to standardized format
def convert_time_units(time_str):

    # Set default value of result to None
    result = None

    # Regular expression pattern to match time units
    pattern = r"(\d+)\s*(min|mins|minute|minutes|hour|hours|hr|hrs)"

    # Extract and convert time units
    matches = re.findall(pattern, time_str, re.IGNORECASE)
    if matches:
        time_value, time_unit = matches[0]
        if time_unit.lower() in ['min', 'mins', 'minute', 'minutes']:
            result = time_value
        elif time_unit.lower() in ['hour', 'hours', 'hr', 'hrs']:
            result = str(int(time_value) * 60)

    return result


# Function to extract body part from a title
def extract_body_part(string):
    doc = nlp(string)
    body_part = None
    body_parts = ["FULL_BODY","UPPER_BODY","LOWER_BODY","CHEST_BACK","ARMS","ABS","LEGS","GLUTES"]
    for ent in doc.ents:
        if ent.label_ in body_parts:
            body_part = ent.label_
            break
    return body_part


# Extract workout using regular expressions
def extract_ent_label(string, label):
    doc = nlp(string)
    workout_label = None
    for ent in doc.ents:
        if ent.label_ == label:
            workout_label = ent.label_
            break
    return workout_label



# Create workout time and workout type column by applying function to extract text of entities
videos_df['workoutLength'] = videos_df['title'].apply(lambda x: extract_ent_text(x,"WORKOUT_TIME"))
videos_df['workoutType'] = videos_df['title'].apply(lambda x: extract_ent_text(x, "WORKOUT_TYPE"))

# Apply the function to create a body part column 
videos_df['bodyPart'] = videos_df['title'].apply(extract_body_part)


# Create new columns by applying function to extract the label of entities
labels_to_extract = ["STANDING", "NO_EQUIPMENT", "NO_JUMPING", "LOW_IMPACT", "STRENGTH_TRAINING"]
workout_features_df = pd.DataFrame(columns=['standingWorkout','noEquipment','noJumping','lowImpact','strengthTraining'])

for i in range(len(labels_to_extract)):
    workout_features_df.iloc[:,i] = videos_df['title'].apply(lambda x: extract_ent_label(x,labels_to_extract[i]))

# Add the new columns to the dataframe of workout videos
videos_df = pd.concat([videos_df,workout_features_df], axis=1)


# Convert the description column to string
videos_df['description'] = videos_df['description'].astype(str)

# Use nlp to extract workout time entity from the description if value is missing for workoutLength column
videos_df['workoutLength'] = videos_df.apply(lambda row: extract_ent_text(row['description'], "WORKOUT_TIME") \
                                             if pd.isna(row['workoutLength']) else row['workoutLength'], axis=1)


# Combine the strings separated by commas
videos_df['combinedTags'] = videos_df['tags'].apply(lambda x: ', '.join(x) if x is not None else x)

# Use nlp to extract workout time entity from the tags if value is missing for workoutLength column
videos_df['workoutLength'] = videos_df.apply(lambda row: extract_ent_text(row['combinedTags'], "WORKOUT_TIME")  \
                                             if pd.isna(row['workoutLength']) and \
                                             row['combinedTags'] is not None else row['workoutLength'],
                                             axis=1)


videos_df[videos_df['workoutLength'].isna()][['title','description','durationMins','combinedTags']]


# List of keywords to drop rows containing them in the tags
keywords = ['travel', 'trip', 'food', 'what I eat',
            'fashion', 'outfit', 'transformation',
            'vlog', 'day in my life']

# Create a regular expression pattern from the keywords
pattern = '|'.join(keywords)

# Filter out the rows that have a partial match with any of the keywords
notworkouts_df= videos_df[(videos_df['workoutLength'].isna()) & (videos_df['combinedTags'].fillna('').str.contains('|'.join(keywords)))]

# Drop the subset to get workout videos only
videos_df = videos_df.drop(notworkouts_df.index)



# Function to convert time units to minutes
def convert_time_units(time_str):
    # Set default return value to None
    result = None
    
    # Regular expression pattern to match time units
    pattern = r"(\d+)\s*(min|mins|minute|minutes|hour|hours|hr|hrs)"
    
    # Extract and convert time units
    matches = re.findall(pattern, time_str, re.IGNORECASE)
    if matches:
        time_value, time_unit = matches[0]
        
        if time_unit.lower() in ['min', 'mins', 'minute', 'minutes']:
            result = int(time_value)
        elif time_unit.lower() in ['hour', 'hours', 'hr', 'hrs']:
            result = int(time_value) * 60
    
    return result


# Standardize the derived workoutLength column so they all have the same units (mins)
videos_df['workoutLength_mins'] = videos_df['workoutLength'].apply(lambda x: convert_time_units(str(x)))


# Check the distribution of workout length after filling in missing values for outliers
videos_df['workoutLength_mins'].describe()


videos_df[videos_df['workoutLength_mins'] > 30][['title','description','durationMins','combinedTags']]


# Save dataframes as csv files 
channels_df.to_csv("../data/processed/fitness_channels_processed_2023_06_28.csv", index=False)
videos_df.to_csv("../data/processed/fitness_videos_processed_2023_06_28.csv", index=False)
