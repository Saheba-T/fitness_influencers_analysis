import os
import re
import ast
import pandas as pd
import numpy as np
import spacy         # Natural language processing
import isodate       # Date transformation and manipulation

from dateutil import parser


# Get current working directory
cwd = os.path.dirname(os.getcwd())
# Create filepath to the raw subfolder in data folder
path = cwd + "/data/raw"

# Read in the csv files from the raw data folder
channels_df = pd.read_csv(path + "/fitness_channels_2023_06_28.csv")
videos_df = pd.read_csv(path + "/fitness_videos_2023_06_28.csv")


channels_df.head()


videos_df.head()


# check for duplicate rows in channels and videos data
(channels_df.duplicated().any(),videos_df.duplicated().any())


channels_df.isnull().any()


videos_df.isnull().any()


# Find the percentage of missing values from columns that contains them in the videos dataframe
missingval_columns = videos_df.loc[:, ['description', 'tags', 'likeCount','favouriteCount','commentCount']]
missingval_columns.isnull().sum() / missingval_columns.shape[0] * 100.00


# Drop the favouriteCount column since it only contains missing values
videos_df.drop('favouriteCount', axis=1, inplace=True)


# Find the unique values of the definition column
videos_df['definition'].unique()


# Check the percentage of each unique value in the definition column
videos_df['definition'].value_counts() / videos_df['definition'].shape[0] * 100


# Drop the definition column for being uninformative
videos_df.drop('definition', axis=1, inplace=True)


# Check the date values to make sure there are no errors
videos_df.publishedAt.sort_values()


channels_df.dtypes


videos_df.dtypes


# Create publish datetime and year for channels data
channels_df['publishedDatetime'] =  channels_df['PublishedDate'].apply(lambda x: parser.parse(x))
channels_df['publishedYear'] = channels_df['publishedDatetime'].apply(lambda x: int(x.strftime("%Y")))


# Title character length
videos_df['titleLength'] = videos_df['title'].apply(lambda x: len(x))


# Convert duration to seconds
videos_df['durationSecs'] = videos_df['duration'].apply(lambda x: isodate.parse_duration(x))
videos_df['durationSecs'] = videos_df['durationSecs'].astype('timedelta64[s]')


# Create publish year and month (of the year) columns
videos_df['publishedDatetime'] = videos_df['publishedAt'].apply(lambda x: parser.parse(x))
videos_df['publishedDatetime'] = videos_df['publishedAt'].apply(lambda x: parser.parse(x))
videos_df['publishedYear'] = videos_df['publishedDatetime'].apply(lambda x: int(x.strftime("%Y")))
videos_df['publishedMonth'] = videos_df['publishedDatetime'].apply(lambda x: x.strftime("%b"))

# Create publish day (of the week) and hour and time of day columns
videos_df['pushblishDayName'] = videos_df['publishedDatetime'].apply(lambda x: x.strftime("%a")) 
videos_df['publishedHour'] = videos_df['publishedDatetime'].apply(lambda x: x.strftime("%H"))
videos_df['publishedToD'] = videos_df['publishedDatetime'].apply(lambda x: x.strftime("%p"))


# Create the number of tags column
videos_df['tags'] = videos_df['tags'].replace(np.nan, None)
videos_df['tags'] = videos_df['tags'].apply(lambda x: x if x is None else ast.literal_eval(x))
videos_df['tagsCount'] = videos_df['tags'].apply(lambda x: 0 if x is None else len(x))


# Create column to categorize Youtube Shorts
videos_df['youtubeShorts'] = [True if x <= 60 else False for x in videos_df['durationSecs']]


# Subset the videos data to filter out Youtube Shorts
workout_videos_df = videos_df[videos_df['youtubeShorts'] == False].copy()


# Download spacY's small english model
nlp = spacy.load("en_core_web_sm")

# Create and add the EntityRuler
ruler = nlp.add_pipe("entity_ruler", before="ner")


#List of Entities and Patterns
patterns = [
    {"label": "WORKOUT_TIME", "pattern": [{"TEXT": {"REGEX": r"^(\d+)"}},
                                          {"LOWER":{"REGEX": r"^(min|mins|minute|minutes|hour|hours|hr|hrs)$"}}
                                         ]},
    {"label": "FULL_BODY", "pattern": [{"LOWER": {"REGEX": r"(full|total|whole)"}}, {"LOWER": "body"}]},
    {"label": "UPPER_BODY", "pattern": [{"LOWER": "upper"}, {"LOWER": "body"}]},
    {"label": "LOWER_BODY", "pattern": [{"LOWER": "lower"}, {"LOWER": "body"}]},
    {"label": "CHEST_BACK", "pattern": [{"LOWER": {"REGEX": r"(back|chest)"}}, {"ORTH": {"REGEX": r"(and|&)"}} ,{"LOWER": {"REGEX": r"(back|chest)"}}]},
    {"label": "ABS", "pattern": [{"LOWER": {"REGEX": r"(core|ab|abs|plank)"}}]},
    {"label": "ARMS", "pattern": [{"LOWER": {"REGEX": r"arms?"}}]},
    {"label": "LEGS", "pattern": [{"LOWER": {"REGEX": r"(thigh|thighs|leg|legs)"}}]},
    {"label": "GLUTES", "pattern": [{"LOWER": {"REGEX": r"(booty|glute|glutes|butt)"}}]},
    {"label": "WORKOUT_TYPE", "pattern": [{"LOWER": {"REGEX": r"(hiit|cardio|pilates|yoga|dance|tabata|barre|stretch)"}}]},
    {"label": "STANDING", "pattern": [{"LOWER": "standing"}]},
    {"label": "NO_EQUIPMENT", "pattern": [{"LOWER": "no", "LOWER": {"REGEX": r"(equip|equipment|equipments|weight|weights)"}}]},
    {"label": "NO_JUMPING", "pattern": [{"LOWER": "no", "LOWER": "jumping"}]},
    {"label": "LOW_IMPACT", "pattern": [{"LOWER": "low", "LOWER": "impact"}]},
    {"label": "STRENGTH_TRAINING", "pattern": [{"LOWER": {"REGEX": r"(strength|sculpt|sculpting|tone|toning|toned)"}}]}
]


ruler.add_patterns(patterns)


# Extract workout time or type using regular expressions
def extract_ent_text(title, label):
    doc = nlp(title)
    workout_label = None
    for ent in doc.ents:
        if ent.label_ == label:
            workout_label = ent.text
            break
    return workout_label


# Function to convert workout time units to standardized format
def convert_time_units(time_str):

    # Set default value of result to None
    result = None

    # Regular expression pattern to match time units
    pattern = r"(\d+)\s*(min|mins|minute|minutes|hour|hours|hr|hrs)"

    # Extract and convert time units
    matches = re.findall(pattern, time_str, re.IGNORECASE)
    if matches:
        time_value, time_unit = matches[0]
        if time_unit.lower() in ['min', 'mins', 'minute', 'minutes']:
            result = time_value
        elif time_unit.lower() in ['hour', 'hours', 'hr', 'hrs']:
            result = str(int(time_value) * 60)

    return result


# Function to extract body part from a title
def extract_body_part(title):
    doc = nlp(title)
    body_part = None
    body_parts = ["FULL_BODY","UPPER_BODY","LOWER_BODY","CHEST_BACK","ARMS","ABS","LEGS","GLUTES"]
    for ent in doc.ents:
        if ent.label_ in body_parts:
            body_part = ent.label_
            break
    return body_part


# Extract workout using regular expressions
def extract_ent_label(title, label):
    doc = nlp(title)
    workout_label = None
    for ent in doc.ents:
        if ent.label_ == label:
            workout_label = ent.label_
            break
    return workout_label



# Create workout time and workout type column by applying function to extract text of entities
workout_videos_df['workoutTime'] = workout_videos_df['title'].apply(lambda x: extract_ent_text(x,"WORKOUT_TIME"))
workout_videos_df['workoutType'] = workout_videos_df['title'].apply(lambda x: extract_ent_text(x, "WORKOUT_TYPE"))

# Apply the function to create a body part column 
workout_videos_df['bodyPart'] = workout_videos_df['title'].apply(extract_body_part)

# Create new columns by applying function to extract the label of entities
labels_to_extract = ["STANDING", "NO_EQUIPMENT", "NO_JUMPING", "LOW_IMPACT", "STRENGTH_TRAINING"]
workout_features_df = pd.DataFrame(columns=['standingWorkout','noEquipment','noJumping','lowImpact','strengthTraining'])

for i in range(len(labels_to_extract)):
    workout_features_df.iloc[:,i] = workout_videos_df['title'].apply(lambda x: extract_ent_label(x,labels_to_extract[i]))

# Add the new columns to the dataframe of workout videos
workout_videos_df = pd.concat([workout_videos_df,workout_features_df], axis=1)


# Apply the conversion function to the 'workoutTime' column
workout_videos_df['workoutTime'] = workout_videos_df['workoutTime'].apply(lambda x: convert_time_units(str(x)))


# Drop the youtubeShorts column since we know all videos are not one
workout_videos_df.drop(columns='youtubeShorts', inplace=True)


# Get the current working directory; should be the top level project folder
cwd = os.path.dirname(os.getcwd())

# Create file path of where the processed data will be stored
path = cwd + "/data/processed"

# Save dataframes as csv files 
channels_df.to_csv(path + "/fitness_channels_processed_2023_06_28.csv", index=False)
workout_videos_df.to_csv(path + "/fitness_videos_processed_2023_06_28.csv", index=False)
