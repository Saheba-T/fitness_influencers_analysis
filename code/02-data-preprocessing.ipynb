{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adcf37c6-831f-47d6-af97-05de94a42414",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e8e58-7afa-4d66-be51-6bf2c1a4d6f6",
   "metadata": {},
   "source": [
    "First, we are going to clean the data and then we are going to perform feature engineering to enrich the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ed3e1-8316-489a-a048-5969b182f86b",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8bdfa8-8aa6-49cd-ad1c-59782ae8a5f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, we are going to clean the data by:\n",
    "- checking for duplicate rows\n",
    "- checking for missing values\n",
    "- checking the percentage of missing values of each column\n",
    "- checking for any redundant (uninformative) columns\n",
    "- checking the column data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2197680-4917-4213-8e56-60439f0875e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy         # Natural language processing\n",
    "import isodate       # Date transformation and manipulation\n",
    "\n",
    "from os.path import dirname, abspath\n",
    "from dateutil import parser\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f6ff9c-5f7d-4998-bd8f-ec871652d564",
   "metadata": {},
   "source": [
    "#### Read the channels and videos files into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ed0c9af1-fcca-42b0-9067-0356279a3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv files from the raw data folder\n",
    "project_dir = dirname(dirname(abspath(\"02-data-preprocessing.ipynb\")))\n",
    "channels_df = pd.read_csv(project_dir + \"/data/raw/fitness_channels_2023_07_11.csv\")\n",
    "videos_df = pd.read_csv(project_dir + \"/data/raw/fitness_videos_2023_07_11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c2547e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns to make the naming more intuitive and consistent\n",
    "channels_df = channels_df.rename(columns={\n",
    "    'ChannelName': 'channel',\n",
    "    'ChannelDescription': 'channel_description',\n",
    "    'PublishedDate': 'published_date',\n",
    "    'TotalSubscribers': 'total_subscribers',\n",
    "    'TotalViews':'total_views',\n",
    "    'TotalVideos': 'total_videos', \n",
    "    'playlistID': 'playlist_id'\n",
    "    \n",
    "})\n",
    "\n",
    "videos_df = videos_df.rename(columns={\n",
    "    'channelTitle': 'channel',\n",
    "    'viewCount': 'total_views',\n",
    "    'likeCount': 'total_likes',\n",
    "    'commentCount': 'total_comments',\n",
    "    'favouriteCount': 'total_favourites',\n",
    "    'publishedAt': 'published_at'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e003d3-1aa4-42c5-a978-e953b7071580",
   "metadata": {},
   "source": [
    "#### Check for duplicate rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c40d1ab-68a3-4170-8c29-5c808b289dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate rows in channels and videos data\n",
    "(channels_df.duplicated().any(),videos_df.duplicated().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a9230-badf-4965-b561-b1f538e3aa50",
   "metadata": {},
   "source": [
    "#### Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fd67da71-e057-4a53-a1ac-cba14a5a0e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id            False\n",
       "channel             False\n",
       "title               False\n",
       "description          True\n",
       "tags                 True\n",
       "published_at        False\n",
       "total_views         False\n",
       "total_likes          True\n",
       "total_favourites     True\n",
       "total_comments       True\n",
       "duration            False\n",
       "definition          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c8146-32bd-40e8-b72c-840deb7ed216",
   "metadata": {},
   "source": [
    "#### Check for percentage of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "60dd4663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id              0.000000\n",
       "channel               0.000000\n",
       "title                 0.000000\n",
       "description           4.554311\n",
       "tags                 12.883585\n",
       "published_at          0.000000\n",
       "total_views           0.000000\n",
       "total_likes           1.217730\n",
       "total_favourites    100.000000\n",
       "total_comments        0.243546\n",
       "duration              0.000000\n",
       "definition            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df.isnull().sum() / videos_df.shape[0] * 100.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "424698ba-81dd-45e9-97d0-208efaa15577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values for likes - those videos are shorts\n",
    "videos_df = videos_df.dropna(subset=['total_likes'])\n",
    "\n",
    "# Drop the favouriteCount column since it only contains missing values\n",
    "videos_df = videos_df.drop(columns='total_favourites')\n",
    "\n",
    "# Fill missing comments with 0 - comments was not allowed for those videos\n",
    "videos_df['total_comments'] = videos_df['total_comments'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70728b86-4158-4ed0-9b9c-959371da7722",
   "metadata": {},
   "source": [
    "#### Check for redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "71092279-0d60-4eff-8dba-77ace2374f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hd    99.556213\n",
       "sd     0.443787\n",
       "Name: definition, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the percentage of each unique value in the definition column\n",
    "videos_df['definition'].value_counts() / videos_df['definition'].shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c1e3ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the definition column for being uninformative\n",
    "videos_df = videos_df.drop(columns='definition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9568b410-d3d8-4442-8e1a-fb2db91516e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2836    2009-10-06T04:47:37Z\n",
       "2835    2009-11-04T18:05:19Z\n",
       "2834    2009-11-10T05:18:29Z\n",
       "2833    2009-11-18T06:49:44Z\n",
       "2832    2009-11-30T08:13:39Z\n",
       "                ...         \n",
       "2837    2023-07-10T15:00:09Z\n",
       "733     2023-07-11T12:46:31Z\n",
       "1652    2023-07-11T13:00:16Z\n",
       "0       2023-07-11T14:00:17Z\n",
       "1241    2023-07-11T14:00:39Z\n",
       "Name: published_at, Length: 4056, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the date values to make sure there are no errors\n",
    "videos_df.published_at.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50fee46-6a54-4c0e-84ee-5b76d571b9ff",
   "metadata": {},
   "source": [
    "#### Checking the column data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "87e8c21f-ca90-4da4-a527-9d17c9eb9cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           object\n",
       "channel            object\n",
       "title              object\n",
       "description        object\n",
       "tags               object\n",
       "published_at       object\n",
       "total_views         int64\n",
       "total_likes       float64\n",
       "total_comments    float64\n",
       "duration           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00424cb-d964-4b1c-9bc6-37c7f47e77ee",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7bea67-de6b-4ac7-8236-0e50fba8ba19",
   "metadata": {},
   "source": [
    "Second, we are going to perform feature engineering to enrich the data by:\n",
    "* Convert ISO 8601 duration format from the YouTube Data API v3\n",
    "    1. First convert to timedelta[s]\n",
    "    2. Convert duration from units of seconds to minutes since it is more intuitive for workout videos\n",
    "    3. Check for any errors or outliers (address them if necessary)\n",
    "    4. Categorize the duration columns into groups\n",
    "* Derive new features from the published date column \n",
    "    1. Get published year\n",
    "    2. Get published month\n",
    "    3. Get published day of the week\n",
    "    4. Get the age of the video\n",
    "* Get the length of the video title\n",
    "* Get the total number of tags in the tags column\n",
    "* use natural language processing (via spaCy) to derive useful features from the video title, description, and/or tags\n",
    "    1. Get the workout length; since actual workout duration and video duration are usually not the same\n",
    "    2. Get the workout type (cardio, HIIT, yoga, pilates, etc..)\n",
    "    3. Get the target body part (legs, abs, arms ,etc..)\n",
    "    3. Get any special aspect of the workout (no jumping, standing, no equipment, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e820695d-48bb-41a3-8f1e-bd5837e4b397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4056.000000\n",
       "mean       10.891958\n",
       "std         9.208619\n",
       "min         0.000000\n",
       "25%         3.962500\n",
       "50%        10.691667\n",
       "75%        14.575000\n",
       "max       130.816667\n",
       "Name: duration_mins, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert duration to seconds\n",
    "videos_df['duration_secs'] = videos_df['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "videos_df['duration_mins'] = videos_df['duration_secs'].astype('timedelta64[s]')/60\n",
    "\n",
    "# Check the distribution of the video duration for presence of any outliers\n",
    "videos_df['duration_mins'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b85b794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping videos that have 0 mins as duration - most likely livestreams that might have accidentally got turned on and off right away\n",
    "videos_df = videos_df[videos_df['duration_mins'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1f36611c-8d9d-49a0-9ce3-09a0651dcb28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>emi wong</td>\n",
       "      <td>45 MIN WALKING CARDIO WORKOUT | Intense Full B...</td>\n",
       "      <td>PT45M18S</td>\n",
       "      <td>fIDmwKCJmlA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>emi wong</td>\n",
       "      <td>45 min Full Body Workout to BURN MAX CALORIES ...</td>\n",
       "      <td>PT47M58S</td>\n",
       "      <td>Wgm1Xc25imM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>emi wong</td>\n",
       "      <td>1 HOUR FULL BODY FAT BURN HOME WORKOUT (Warm U...</td>\n",
       "      <td>PT1H2M35S</td>\n",
       "      <td>p188evCXF0k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>emi wong</td>\n",
       "      <td>2 Weeks Workout Program to Lose Weight, Get Ab...</td>\n",
       "      <td>PT1H4M51S</td>\n",
       "      <td>EJKw3Mh0MyI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>emi wong</td>\n",
       "      <td>45-min Full Body Fat Burn HIIT at home with NO...</td>\n",
       "      <td>PT46M43S</td>\n",
       "      <td>wAIRYalt75w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>Chloe Ting</td>\n",
       "      <td>Abs &amp; Booty Workout Livestream</td>\n",
       "      <td>PT1H34M6S</td>\n",
       "      <td>tahd5q-onKc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>Chloe Ting</td>\n",
       "      <td>10 Million Subs LIVESTREAM | Let's hangout + W...</td>\n",
       "      <td>PT2H10M49S</td>\n",
       "      <td>IdO0Ie3_2QU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>Chloe Ting</td>\n",
       "      <td>2000 REP Full Body &amp; Abs Workout CHALLENGE for...</td>\n",
       "      <td>PT49M48S</td>\n",
       "      <td>004CudS_3Ew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>Chloe Ting</td>\n",
       "      <td>45 Min Full Body FAT BURN Workout | Get Flat A...</td>\n",
       "      <td>PT46M53S</td>\n",
       "      <td>LDvAuqTZxMw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>blogilates</td>\n",
       "      <td>POPFLEX Pre-Black Friday Extravaganza</td>\n",
       "      <td>PT1H12M46S</td>\n",
       "      <td>HO84VmEkfq0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>blogilates</td>\n",
       "      <td>*Special* Full Length 1 Hour POP Pilates Class!</td>\n",
       "      <td>PT1H8M47S</td>\n",
       "      <td>s0CkBw5Wock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>blogilates</td>\n",
       "      <td>Can I do 1000 Squats? FULL LENGTH Version</td>\n",
       "      <td>PT45M16S</td>\n",
       "      <td>fF71IJUXGOk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>Rebecca-Louise</td>\n",
       "      <td>FULL BODY FAT LOSS 🔥 30 min at Home Workout + ...</td>\n",
       "      <td>PT55M16S</td>\n",
       "      <td>_NOGXxLGQ0A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>Rebecca-Louise</td>\n",
       "      <td>LEAN OUT Live Workout | Q&amp;A with Rebecca Louis...</td>\n",
       "      <td>PT45M35S</td>\n",
       "      <td>AKzN3-JBOvU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>Rebecca-Louise</td>\n",
       "      <td>30 minutes FLAT TUMMY &amp; THIGH GAP at home work...</td>\n",
       "      <td>PT45M36S</td>\n",
       "      <td>hx6E8eTOmNs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>Rebecca-Louise</td>\n",
       "      <td>30 minute ROUND BOOTY &amp; SMALL WIAST workout (b...</td>\n",
       "      <td>PT46M</td>\n",
       "      <td>_pJTjFQLR_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>Rebecca-Louise</td>\n",
       "      <td>LOSE FAT AND GET TONED in 40 minutes from home</td>\n",
       "      <td>PT47M35S</td>\n",
       "      <td>s0H3x9pH7yk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3621</th>\n",
       "      <td>Rebecca-Louise</td>\n",
       "      <td>Master the mental &amp; the POWER of visualization...</td>\n",
       "      <td>PT51M52S</td>\n",
       "      <td>0o4JRqqZmb4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>Rebecca-Louise</td>\n",
       "      <td>Know your value and OWN your self-worth | Rebe...</td>\n",
       "      <td>PT48M47S</td>\n",
       "      <td>G25aQB1sCWQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3642</th>\n",
       "      <td>Rebecca-Louise</td>\n",
       "      <td>Building a BUSINESS &amp; how to create VIRAL VIDE...</td>\n",
       "      <td>PT56M20S</td>\n",
       "      <td>wmF_P2QhB3M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             channel                                              title  \\\n",
       "822         emi wong  45 MIN WALKING CARDIO WORKOUT | Intense Full B...   \n",
       "930         emi wong  45 min Full Body Workout to BURN MAX CALORIES ...   \n",
       "991         emi wong  1 HOUR FULL BODY FAT BURN HOME WORKOUT (Warm U...   \n",
       "1013        emi wong  2 Weeks Workout Program to Lose Weight, Get Ab...   \n",
       "1094        emi wong  45-min Full Body Fat Burn HIIT at home with NO...   \n",
       "1389      Chloe Ting                     Abs & Booty Workout Livestream   \n",
       "1409      Chloe Ting  10 Million Subs LIVESTREAM | Let's hangout + W...   \n",
       "1451      Chloe Ting  2000 REP Full Body & Abs Workout CHALLENGE for...   \n",
       "1517      Chloe Ting  45 Min Full Body FAT BURN Workout | Get Flat A...   \n",
       "1737      blogilates              POPFLEX Pre-Black Friday Extravaganza   \n",
       "2294      blogilates    *Special* Full Length 1 Hour POP Pilates Class!   \n",
       "2602      blogilates          Can I do 1000 Squats? FULL LENGTH Version   \n",
       "3047  Rebecca-Louise  FULL BODY FAT LOSS 🔥 30 min at Home Workout + ...   \n",
       "3123  Rebecca-Louise  LEAN OUT Live Workout | Q&A with Rebecca Louis...   \n",
       "3340  Rebecca-Louise  30 minutes FLAT TUMMY & THIGH GAP at home work...   \n",
       "3341  Rebecca-Louise  30 minute ROUND BOOTY & SMALL WIAST workout (b...   \n",
       "3366  Rebecca-Louise     LOSE FAT AND GET TONED in 40 minutes from home   \n",
       "3621  Rebecca-Louise  Master the mental & the POWER of visualization...   \n",
       "3624  Rebecca-Louise  Know your value and OWN your self-worth | Rebe...   \n",
       "3642  Rebecca-Louise  Building a BUSINESS & how to create VIRAL VIDE...   \n",
       "\n",
       "        duration     video_id  \n",
       "822     PT45M18S  fIDmwKCJmlA  \n",
       "930     PT47M58S  Wgm1Xc25imM  \n",
       "991    PT1H2M35S  p188evCXF0k  \n",
       "1013   PT1H4M51S  EJKw3Mh0MyI  \n",
       "1094    PT46M43S  wAIRYalt75w  \n",
       "1389   PT1H34M6S  tahd5q-onKc  \n",
       "1409  PT2H10M49S  IdO0Ie3_2QU  \n",
       "1451    PT49M48S  004CudS_3Ew  \n",
       "1517    PT46M53S  LDvAuqTZxMw  \n",
       "1737  PT1H12M46S  HO84VmEkfq0  \n",
       "2294   PT1H8M47S  s0CkBw5Wock  \n",
       "2602    PT45M16S  fF71IJUXGOk  \n",
       "3047    PT55M16S  _NOGXxLGQ0A  \n",
       "3123    PT45M35S  AKzN3-JBOvU  \n",
       "3340    PT45M36S  hx6E8eTOmNs  \n",
       "3341       PT46M  _pJTjFQLR_8  \n",
       "3366    PT47M35S  s0H3x9pH7yk  \n",
       "3621    PT51M52S  0o4JRqqZmb4  \n",
       "3624    PT48M47S  G25aQB1sCWQ  \n",
       "3642    PT56M20S  wmF_P2QhB3M  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for videos that are extremely long, greater than 45 mins.\n",
    "# Note: we get that there are 20 videos that are that long\n",
    "videos_df[videos_df['duration_mins'] > 45][['channel','title','duration','video_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3b3d5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges for the duration ranges\n",
    "bin_edges = [0, 5, 10, 20, 30, 45, float('inf')]\n",
    "\n",
    "# Define the labels for each range\n",
    "labels = ['0-5', '5-10', '10-20', '20-30', '30-45', '45+']\n",
    "\n",
    "# Use pd.cut to categorize the 'duration_mins' column into the specified ranges\n",
    "videos_df['duration_category'] = pd.cut(videos_df['duration_mins'], bins=bin_edges, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6fdbbad8-a1d5-474e-b2e9-6ea4ee283120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publish year and month (of the year) columns\n",
    "videos_df['published_datetime'] = pd.to_datetime(videos_df['published_at'].apply(lambda x: parser.parse(x)))\n",
    "videos_df['published_date'] = pd.to_datetime(videos_df['published_datetime'].dt.date)\n",
    "\n",
    "# Extract the month and year from the 'published_date' to create new columns\n",
    "videos_df['published_month'] = videos_df['published_date'].dt.month\n",
    "videos_df['published_year'] = videos_df['published_date'].dt.year\n",
    "\n",
    "# Get the current date \n",
    "current_date_str = date.today()\n",
    "current_date = pd.to_datetime(current_date_str)\n",
    "\n",
    "# Calculate the video age in months\n",
    "videos_df['video_age'] = ((current_date.year - videos_df['published_year']) * 12 +\n",
    "                         (current_date.month - videos_df['published_month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7fb05ca4-520a-4b9a-9bf4-64bb00028cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the description column to string\n",
    "videos_df['description'] = videos_df['description'].astype(str)\n",
    "\n",
    "# Title character length\n",
    "videos_df['title_length'] = videos_df['title'].str.len()\n",
    "\n",
    "# Create the number of tags column\n",
    "videos_df['tags'] = videos_df['tags'].replace(np.nan, None)\n",
    "videos_df['tags'] = videos_df['tags'].apply(lambda x: x if x is None else ast.literal_eval(x))\n",
    "videos_df['total_tags'] = videos_df['tags'].apply(lambda x: 0 if x is None else len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dd073096-afcd-49b6-b1a9-e88651905b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we are going to use spaCy's entity ruler along with regex \n",
    "# to look for specific entities in the text columns.\n",
    "\n",
    "# Download spaCy's small english model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create and add the EntityRuler\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "#List of Entities and Patterns\n",
    "patterns = [\n",
    "    # labels for body part target\n",
    "    {\"label\": \"FULL_BODY\", \"pattern\": [{\"LOWER\": {\"REGEX\": r\"(full|total|whole)\"}}, {\"LOWER\": \"body\"}]},\n",
    "    {\"label\": \"UPPER_BODY\", \"pattern\": [{\"LOWER\": \"upper\"}, {\"LOWER\": \"body\"}]},\n",
    "    {\"label\": \"LOWER_BODY\", \"pattern\": [{\"LOWER\": \"lower\"}, {\"LOWER\": \"body\"}]},\n",
    "    {\"label\": \"CHEST\", \"pattern\": [{\"LOWER\": \"chest\"}]},\n",
    "    {\"label\": \"BACK\", \"pattern\": [{\"LOWER\": \"back\"}]},\n",
    "    {\"label\": \"ABS\", \"pattern\": [{\"LOWER\": {\"REGEX\": r\"(core|ab|abs|plank)\"}}]},\n",
    "    {\"label\": \"ARMS\", \"pattern\": [{\"LOWER\": {\"REGEX\": r\"arms?\"}}]},\n",
    "    {\"label\": \"LEGS\", \"pattern\": [{\"LOWER\": {\"REGEX\": r\"(thigh|thighs|leg|legs)\"}}]},\n",
    "    {\"label\": \"GLUTES\", \"pattern\": [{\"LOWER\": {\"REGEX\": r\"(booty|glute|glutes|butt)\"}}]},\n",
    "    # labels for workout type\n",
    "    {\"label\": \"HIIT\", \"pattern\": [{\"LOWER\": \"hiit\"}]},\n",
    "    {\"label\": \"CARDIO\", \"pattern\": [{\"LOWER\": \"cardio\"}]},\n",
    "    {\"label\": \"DANCE\", \"pattern\": [{\"LOWER\": \"dance\"}]},\n",
    "    {\"label\": \"TABATA\", \"pattern\": [{\"LOWER\": \"tabata\"}]},\n",
    "    {\"label\": \"PILATES\", \"pattern\": [{\"LOWER\": \"pilates\"}]},\n",
    "    {\"label\": \"BARRE\", \"pattern\": [{\"LOWER\": \"barre\"}]},\n",
    "    {\"label\": \"YOGA\", \"pattern\": [{\"LOWER\": \"yoga\"}]},\n",
    "    {\"label\": \"STANDING\", \"pattern\": [{\"LOWER\": \"standing\"}]},\n",
    "    {\"label\": \"NO_EQUIPMENT\", \"pattern\": [{\"LOWER\": \"no\", \"LOWER\": {\"REGEX\": r\"(equip|equipment|equipments|weight|weights)\"}}]},\n",
    "    {\"label\": \"NO_JUMPING\", \"pattern\": [{\"LOWER\": \"no\", \"LOWER\": \"jumping\"}]},\n",
    "    {\"label\": \"LOW_IMPACT\", \"pattern\": [{\"LOWER\": \"low\", \"LOWER\": \"impact\"}]},\n",
    "    {\"label\": \"STRENGTH_TRAINING\", \"pattern\": [{\"LOWER\": {\"REGEX\": r\"(strength|sculpt|sculpting|tone|toning|toned)\"}}]}\n",
    "]\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5e7515c5-09b3-4741-9488-34e72197d4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_ent_label(string, label):\n",
    "    \"\"\" Identify presence of label using regular expressions\n",
    "\n",
    "    Arguments:\n",
    "        string -- the string value of either the title, description columns\n",
    "        label -- can be either one of the labels mentioned in the patterns list above\n",
    "\n",
    "    Returns:\n",
    "        A logical value, True if the label is found, else the default value is False\n",
    "    \"\"\"\n",
    "    doc = nlp(string)\n",
    "    result = False\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == label:\n",
    "            result = True\n",
    "            break\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "05eb8037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting video text information for column: FULL_BODY\n",
      "Getting video text information for column: UPPER_BODY\n",
      "Getting video text information for column: LOWER_BODY\n",
      "Getting video text information for column: CHEST\n",
      "Getting video text information for column: BACK\n",
      "Getting video text information for column: ABS\n",
      "Getting video text information for column: ARMS\n",
      "Getting video text information for column: LEGS\n",
      "Getting video text information for column: GLUTES\n",
      "Getting video text information for column: HIIT\n",
      "Getting video text information for column: CARDIO\n",
      "Getting video text information for column: DANCE\n",
      "Getting video text information for column: TABATA\n",
      "Getting video text information for column: PILATES\n",
      "Getting video text information for column: BARRE\n",
      "Getting video text information for column: YOGA\n",
      "Getting video text information for column: STANDING\n",
      "Getting video text information for column: NO_EQUIPMENT\n",
      "Getting video text information for column: NO_JUMPING\n",
      "Getting video text information for column: LOW_IMPACT\n",
      "Getting video text information for column: STRENGTH_TRAINING\n"
     ]
    }
   ],
   "source": [
    "# Extract the values for the \"label\" key and store them as a list\n",
    "labels_list = [pattern['label'] for pattern in patterns]\n",
    "\n",
    "# Create new columns to the exting videos dataframe\n",
    "videos_df = videos_df.assign(**{label: None for label in labels_list})\n",
    "\n",
    "# Apply the extract_ent_label function to the new columns row-wise using apply and lambda function\n",
    "for label in labels_list:\n",
    "    print(\"Getting video text information for column: \" + label)\n",
    "    \n",
    "    # extract text information about the workout from the video title first\n",
    "    videos_df[label] = videos_df.apply(lambda row: extract_ent_label(row['title'], label), axis=1)\n",
    "\n",
    "    # if missing from the title, extract text information about the workout from the video description\n",
    "    videos_df[label] = videos_df.apply(lambda row: extract_ent_label(row['description'], label)\\\n",
    "        if (not row[label]) else row[label], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6e47c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4052 entries, 0 to 4105\n",
      "Data columns (total 38 columns):\n",
      " #   Column              Non-Null Count  Dtype                  \n",
      "---  ------              --------------  -----                  \n",
      " 0   video_id            4052 non-null   object                 \n",
      " 1   channel             4052 non-null   category               \n",
      " 2   title               4052 non-null   object                 \n",
      " 3   description         4052 non-null   object                 \n",
      " 4   tags                3537 non-null   object                 \n",
      " 5   total_views         4052 non-null   int64                  \n",
      " 6   total_likes         4052 non-null   float64                \n",
      " 7   total_comments      4052 non-null   float64                \n",
      " 8   duration_mins       4052 non-null   float64                \n",
      " 9   duration_category   4052 non-null   category               \n",
      " 10  published_datetime  4052 non-null   datetime64[ns, tzutc()]\n",
      " 11  published_date      4052 non-null   datetime64[ns]         \n",
      " 12  published_month     4052 non-null   int64                  \n",
      " 13  published_year      4052 non-null   int64                  \n",
      " 14  video_age           4052 non-null   int64                  \n",
      " 15  title_length        4052 non-null   int64                  \n",
      " 16  total_tags          4052 non-null   int64                  \n",
      " 17  FULL_BODY           4052 non-null   bool                   \n",
      " 18  UPPER_BODY          4052 non-null   bool                   \n",
      " 19  LOWER_BODY          4052 non-null   bool                   \n",
      " 20  CHEST               4052 non-null   bool                   \n",
      " 21  BACK                4052 non-null   bool                   \n",
      " 22  ABS                 4052 non-null   bool                   \n",
      " 23  ARMS                4052 non-null   bool                   \n",
      " 24  LEGS                4052 non-null   bool                   \n",
      " 25  GLUTES              4052 non-null   bool                   \n",
      " 26  HIIT                4052 non-null   bool                   \n",
      " 27  CARDIO              4052 non-null   bool                   \n",
      " 28  DANCE               4052 non-null   bool                   \n",
      " 29  TABATA              4052 non-null   bool                   \n",
      " 30  PILATES             4052 non-null   bool                   \n",
      " 31  BARRE               4052 non-null   bool                   \n",
      " 32  YOGA                4052 non-null   bool                   \n",
      " 33  STANDING            4052 non-null   bool                   \n",
      " 34  NO_EQUIPMENT        4052 non-null   bool                   \n",
      " 35  NO_JUMPING          4052 non-null   bool                   \n",
      " 36  LOW_IMPACT          4052 non-null   bool                   \n",
      " 37  STRENGTH_TRAINING   4052 non-null   bool                   \n",
      "dtypes: bool(21), category(2), datetime64[ns, tzutc()](1), datetime64[ns](1), float64(3), int64(6), object(4)\n",
      "memory usage: 597.9+ KB\n"
     ]
    }
   ],
   "source": [
    "videos_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "422cb637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns we no longer need\n",
    "videos_df = videos_df.drop(columns=['duration','published_at','duration_secs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66e1fae-a080-4cbe-92a2-322ad8efaf11",
   "metadata": {},
   "source": [
    "#### Save the processed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6c54b331-8415-4197-a0d1-75f12f914e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes as csv files in the processed subfolder of the data folder\n",
    "channels_df.to_csv(project_dir + \"/data/processed/fitness_channels_processed_2023_07_11.csv\", index=False)\n",
    "videos_df.to_csv(project_dir + \"/data/processed/fitness_videos_processed_2023_07_11.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
